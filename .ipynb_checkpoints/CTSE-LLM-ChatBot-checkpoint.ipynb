{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7554e865-d430-4ab0-8bbf-79d0667b52f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: openai in c:\\users\\user\\appdata\\roaming\\python\\python313\\site-packages (1.76.0)\n",
      "Collecting PyPDF2\n",
      "  Using cached pypdf2-3.0.1-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\user\\appdata\\roaming\\python\\python313\\site-packages (2.1.3)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\user\\appdata\\roaming\\python\\python313\\site-packages (1.5.2)\n",
      "Requirement already satisfied: ipywidgets in c:\\users\\user\\appdata\\roaming\\python\\python313\\site-packages (8.1.5)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\user\\appdata\\roaming\\python\\python313\\site-packages (from openai) (4.6.2.post1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\user\\appdata\\roaming\\python\\python313\\site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\user\\appdata\\roaming\\python\\python313\\site-packages (from openai) (0.27.2)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\user\\appdata\\roaming\\python\\python313\\site-packages (from openai) (0.9.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\user\\appdata\\roaming\\python\\python313\\site-packages (from openai) (2.11.3)\n",
      "Requirement already satisfied: sniffio in c:\\users\\user\\appdata\\roaming\\python\\python313\\site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\user\\appdata\\roaming\\python\\python313\\site-packages (from openai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in c:\\users\\user\\appdata\\roaming\\python\\python313\\site-packages (from openai) (4.12.2)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\user\\appdata\\roaming\\python\\python313\\site-packages (from scikit-learn) (1.14.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\user\\appdata\\roaming\\python\\python313\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\user\\appdata\\roaming\\python\\python313\\site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: comm>=0.1.3 in c:\\users\\user\\appdata\\roaming\\python\\python313\\site-packages (from ipywidgets) (0.2.2)\n",
      "Requirement already satisfied: ipython>=6.1.0 in c:\\users\\user\\appdata\\roaming\\python\\python313\\site-packages (from ipywidgets) (8.29.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in c:\\users\\user\\appdata\\roaming\\python\\python313\\site-packages (from ipywidgets) (5.14.3)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.12 in c:\\users\\user\\appdata\\roaming\\python\\python313\\site-packages (from ipywidgets) (4.0.13)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0.12 in c:\\users\\user\\appdata\\roaming\\python\\python313\\site-packages (from ipywidgets) (3.0.13)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\user\\appdata\\roaming\\python\\python313\\site-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
      "Requirement already satisfied: certifi in c:\\users\\user\\appdata\\roaming\\python\\python313\\site-packages (from httpx<1,>=0.23.0->openai) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\user\\appdata\\roaming\\python\\python313\\site-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\user\\appdata\\roaming\\python\\python313\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: decorator in c:\\users\\user\\appdata\\roaming\\python\\python313\\site-packages (from ipython>=6.1.0->ipywidgets) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\users\\user\\appdata\\roaming\\python\\python313\\site-packages (from ipython>=6.1.0->ipywidgets) (0.19.2)\n",
      "Requirement already satisfied: matplotlib-inline in c:\\users\\user\\appdata\\roaming\\python\\python313\\site-packages (from ipython>=6.1.0->ipywidgets) (0.1.7)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in c:\\users\\user\\appdata\\roaming\\python\\python313\\site-packages (from ipython>=6.1.0->ipywidgets) (3.0.48)\n",
      "Requirement already satisfied: pygments>=2.4.0 in c:\\users\\user\\appdata\\roaming\\python\\python313\\site-packages (from ipython>=6.1.0->ipywidgets) (2.18.0)\n",
      "Requirement already satisfied: stack-data in c:\\users\\user\\appdata\\roaming\\python\\python313\\site-packages (from ipython>=6.1.0->ipywidgets) (0.6.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\appdata\\roaming\\python\\python313\\site-packages (from ipython>=6.1.0->ipywidgets) (0.4.6)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\user\\appdata\\roaming\\python\\python313\\site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.1 in c:\\users\\user\\appdata\\roaming\\python\\python313\\site-packages (from pydantic<3,>=1.9.0->openai) (2.33.1)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\user\\appdata\\roaming\\python\\python313\\site-packages (from pydantic<3,>=1.9.0->openai) (0.4.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in c:\\users\\user\\appdata\\roaming\\python\\python313\\site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.4)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\user\\appdata\\roaming\\python\\python313\\site-packages (from prompt-toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets) (0.2.13)\n",
      "Requirement already satisfied: executing>=1.2.0 in c:\\users\\user\\appdata\\roaming\\python\\python313\\site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.1.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in c:\\users\\user\\appdata\\roaming\\python\\python313\\site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.4.1)\n",
      "Requirement already satisfied: pure-eval in c:\\users\\user\\appdata\\roaming\\python\\python313\\site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (0.2.3)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\user\\appdata\\roaming\\python\\python313\\site-packages (from asttokens>=2.1.0->stack-data->ipython>=6.1.0->ipywidgets) (1.16.0)\n",
      "Using cached pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
      "Installing collected packages: PyPDF2\n",
      "Successfully installed PyPDF2-3.0.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.1\n",
      "[notice] To update, run: C:\\Program Files\\Python313\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install openai PyPDF2 numpy scikit-learn ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b04fb3da-0f80-45a1-9bf6-6a7fcc6ae6d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "# # CTSE Lecture Notes Chatbot\n",
    "# \n",
    "# This chatbot answers questions based on CTSE lecture notes using OpenRouter's LLM API.\n",
    "\n",
    "# %%\n",
    "# Import required libraries\n",
    "import os\n",
    "import openai\n",
    "from PyPDF2 import PdfReader\n",
    "from typing import List\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, Markdown, clear_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f85c079e-14cd-45f1-b8b3-76d6e51d9a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "class Config:\n",
    "    OPENROUTER_API_KEY = \"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\"  # Replace with your actual API key\n",
    "    OPENROUTER_BASE_URL = \"https://openrouter.ai/api/v1\"\n",
    "    MODEL_NAME = \"mistralai/mistral-7b-instruct\"  # Cost-effective model\n",
    "    TEMPERATURE = 0.3  # Controls randomness of responses\n",
    "    MAX_TOKENS = 1000  # Limit response length\n",
    "    CONTEXT_TOKENS = 3000  # Max context to send to LLM\n",
    "    CHUNK_SIZE = 500  # Size of text chunks for processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "484549f3-7a47-4a91-bbd2-1b78c264928a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize OpenAI client for OpenRouter\n",
    "client = openai.OpenAI(\n",
    "    base_url=Config.OPENROUTER_BASE_URL,\n",
    "    api_key=Config.OPENROUTER_API_KEY\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3b1c2f2e-5597-4af7-8ed9-a451119dd0ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Document Processing Functions\n",
    "def extract_text_from_pdf(pdf_path: str) -> str:\n",
    "    \"\"\"Extract text from a PDF file\"\"\"\n",
    "    text = \"\"\n",
    "    try:\n",
    "        with open(pdf_path, \"rb\") as file:\n",
    "            reader = PdfReader(file)\n",
    "            for page in reader.pages:\n",
    "                text += page.extract_text() or \"\"  # Handle None returns\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading PDF {pdf_path}: {str(e)}\")\n",
    "    return text\n",
    "\n",
    "def chunk_text(text: str, chunk_size: int = Config.CHUNK_SIZE) -> List[str]:\n",
    "    \"\"\"Split text into manageable chunks\"\"\"\n",
    "    words = text.split()\n",
    "    chunks = [' '.join(words[i:i + chunk_size]) for i in range(0, len(words), chunk_size)]\n",
    "    return chunks\n",
    "\n",
    "def create_vector_index(text_chunks: List[str]):\n",
    "    \"\"\"Create TF-IDF vector index for semantic search\"\"\"\n",
    "    vectorizer = TfidfVectorizer(stop_words='english')\n",
    "    tfidf_matrix = vectorizer.fit_transform(text_chunks)\n",
    "    return vectorizer, tfidf_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6425268e-6e26-4632-96c9-9f0c5888c792",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Knowledge Base Class\n",
    "class LectureNotesKB:\n",
    "    def __init__(self):\n",
    "        self.notes = {}\n",
    "        self.vectorizers = {}\n",
    "        self.tfidf_matrices = {}\n",
    "        self.chunks = {}\n",
    "        \n",
    "    def add_lecture(self, lecture_name: str, pdf_path: str):\n",
    "        \"\"\"Add a lecture to the knowledge base\"\"\"\n",
    "        text = extract_text_from_pdf(pdf_path)\n",
    "        if not text:\n",
    "            print(f\"Warning: No text extracted from {pdf_path}\")\n",
    "            return\n",
    "            \n",
    "        chunks = chunk_text(text)\n",
    "        vectorizer, tfidf_matrix = create_vector_index(chunks)\n",
    "        \n",
    "        self.notes[lecture_name] = text\n",
    "        self.chunks[lecture_name] = chunks\n",
    "        self.vectorizers[lecture_name] = vectorizer\n",
    "        self.tfidf_matrices[lecture_name] = tfidf_matrix\n",
    "        print(f\"Loaded lecture: {lecture_name} ({len(chunks)} chunks)\")\n",
    "        \n",
    "    def get_relevant_chunks(self, lecture_name: str, query: str, top_k: int = 3) -> List[str]:\n",
    "        \"\"\"Retrieve most relevant text chunks for a query\"\"\"\n",
    "        if lecture_name not in self.notes:\n",
    "            print(f\"Lecture {lecture_name} not found in knowledge base\")\n",
    "            return []\n",
    "            \n",
    "        vectorizer = self.vectorizers[lecture_name]\n",
    "        tfidf_matrix = self.tfidf_matrices[lecture_name]\n",
    "        \n",
    "        query_vec = vectorizer.transform([query])\n",
    "        similarities = cosine_similarity(query_vec, tfidf_matrix).flatten()\n",
    "        top_indices = similarities.argsort()[-top_k:][::-1]\n",
    "        \n",
    "        return [self.chunks[lecture_name][i] for i in top_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "968dcce4-b00d-4fc9-8dcd-9c01ccfb79fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chatbot Class\n",
    "class LectureChatbot:\n",
    "    def __init__(self):\n",
    "        self.knowledge_base = LectureNotesKB()\n",
    "        self.conversation_history = []\n",
    "        \n",
    "    def load_lecture(self, lecture_name: str, pdf_path: str):\n",
    "        \"\"\"Load lecture notes into the knowledge base\"\"\"\n",
    "        self.knowledge_base.add_lecture(lecture_name, pdf_path)\n",
    "        \n",
    "    def generate_response(self, lecture_name: str, question: str) -> str:\n",
    "        \"\"\"Generate a response to the user's question\"\"\"\n",
    "        # Get relevant context from lecture notes\n",
    "        relevant_chunks = self.knowledge_base.get_relevant_chunks(lecture_name, question)\n",
    "        context = \"\\n\\n\".join(relevant_chunks)[:Config.CONTEXT_TOKENS]\n",
    "        \n",
    "        # Prepare the prompt\n",
    "        system_prompt = f\"\"\"You are an expert teaching assistant for the CTSE course. \n",
    "        Answer the student's question based strictly on the provided lecture notes context.\n",
    "        If the answer isn't in the notes, say \"I don't have that information in my lecture notes.\"\n",
    "        \n",
    "        Lecture Context:\n",
    "        {context}\n",
    "        \"\"\"\n",
    "        \n",
    "        # Add to conversation history\n",
    "        self.conversation_history.append({\"role\": \"user\", \"content\": question})\n",
    "        \n",
    "        try:\n",
    "            # Call OpenRouter API\n",
    "            response = client.chat.completions.create(\n",
    "                model=Config.MODEL_NAME,\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": system_prompt},\n",
    "                    *self.conversation_history\n",
    "                ],\n",
    "                temperature=Config.TEMPERATURE,\n",
    "                max_tokens=Config.MAX_TOKENS\n",
    "            )\n",
    "            \n",
    "            answer = response.choices[0].message.content\n",
    "            self.conversation_history.append({\"role\": \"assistant\", \"content\": answer})\n",
    "            return answer\n",
    "            \n",
    "        except Exception as e:\n",
    "            return f\"Error generating response: {str(e)}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bdab369b-7e58-49a9-b09d-e91e29323ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "# UI Components\n",
    "def create_chat_interface(chatbot: LectureChatbot, lecture_name: str):\n",
    "    \"\"\"Create interactive chat interface\"\"\"\n",
    "    output = widgets.Output()\n",
    "    question_input = widgets.Text(\n",
    "        placeholder='Ask a question about the lecture...',\n",
    "        layout=widgets.Layout(width='80%')\n",
    "    )\n",
    "    \n",
    "    def on_submit(_):\n",
    "        with output:\n",
    "            question = question_input.value\n",
    "            if question.strip():\n",
    "                display(Markdown(f\"**You:** {question}\"))\n",
    "                answer = chatbot.generate_response(lecture_name, question)\n",
    "                display(Markdown(f\"**Assistant:** {answer}\"))\n",
    "                question_input.value = ''\n",
    "    \n",
    "    submit_button = widgets.Button(description=\"Ask\", layout=widgets.Layout(width='20%'))\n",
    "    submit_button.on_click(on_submit)\n",
    "    \n",
    "    input_box = widgets.HBox([question_input, submit_button])\n",
    "    display(widgets.VBox([output, input_box]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "061b0037-fea7-49c7-83f1-6d461dc96818",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main Execution\n",
    "def main():\n",
    "    # Initialize chatbot\n",
    "    chatbot = LectureChatbot()\n",
    "    \n",
    "    # Load lecture notes (replace with actual paths)\n",
    "    LECTURE_NOTES = {\n",
    "        \"CTSE Lectures\": \"ctse_lecture_notes.pdf\",\n",
    "       #\"AI in SE\": \"lectures/ai_in_se.pdf\",\n",
    "       # \"DevOps\": \"lectures/devops.pdf\"\n",
    "    }\n",
    "    \n",
    "    # Create directory if it doesn't exist\n",
    "    os.makedirs(\"lectures\", exist_ok=True)\n",
    "    \n",
    "    # Load available lectures\n",
    "    for name, path in LECTURE_NOTES.items():\n",
    "        if os.path.exists(path):\n",
    "            chatbot.load_lecture(name, path)\n",
    "        else:\n",
    "            print(f\"Lecture file not found: {path}\")\n",
    "    \n",
    "    # Create dropdown for lecture selection\n",
    "    available_lectures = [name for name, path in LECTURE_NOTES.items() if os.path.exists(path)]\n",
    "    if not available_lectures:\n",
    "        print(\"Error: No lecture files found in 'lectures' directory\")\n",
    "        return\n",
    "    \n",
    "    lecture_dropdown = widgets.Dropdown(\n",
    "        options=available_lectures,\n",
    "        description='Select Lecture:',\n",
    "        disabled=False\n",
    "    )\n",
    "    \n",
    "    # Display UI\n",
    "    display(lecture_dropdown)\n",
    "    \n",
    "    def on_lecture_change(change):\n",
    "        if change['type'] == 'change' and change['name'] == 'value':\n",
    "            clear_output(wait=True)\n",
    "            display(lecture_dropdown)\n",
    "            create_chat_interface(chatbot, change['new'])\n",
    "    \n",
    "    lecture_dropdown.observe(on_lecture_change)\n",
    "    create_chat_interface(chatbot, lecture_dropdown.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "698a098f-62e9-4642-87dc-f15eb7f54397",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded lecture: Software Architecture (5 chunks)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa270196801a4d6a8cbfc0a7ad7da1ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Select Lecture:', options=('Software Architecture',), value='Software Architecture')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea4b5404221d49fb9ce7796da9ab2d60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Output(), HBox(children=(Text(value='', layout=Layout(width='80%'), placeholder='Ask a questionâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Run the chatbot\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d90e7b85-b453-4930-87cd-df10a6d2a253",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
