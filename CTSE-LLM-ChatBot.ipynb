{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7554e865-d430-4ab0-8bbf-79d0667b52f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in c:\\users\\user\\anaconda3\\envs\\ctse_env\\lib\\site-packages (1.76.0)\n",
      "Requirement already satisfied: PyPDF2 in c:\\users\\user\\anaconda3\\envs\\ctse_env\\lib\\site-packages (3.0.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\user\\anaconda3\\envs\\ctse_env\\lib\\site-packages (2.2.5)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\user\\anaconda3\\envs\\ctse_env\\lib\\site-packages (1.6.1)\n",
      "Requirement already satisfied: ipywidgets in c:\\users\\user\\anaconda3\\envs\\ctse_env\\lib\\site-packages (8.1.6)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\user\\anaconda3\\envs\\ctse_env\\lib\\site-packages (from openai) (4.9.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\user\\anaconda3\\envs\\ctse_env\\lib\\site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\user\\anaconda3\\envs\\ctse_env\\lib\\site-packages (from openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\user\\anaconda3\\envs\\ctse_env\\lib\\site-packages (from openai) (0.9.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\user\\anaconda3\\envs\\ctse_env\\lib\\site-packages (from openai) (2.11.3)\n",
      "Requirement already satisfied: sniffio in c:\\users\\user\\anaconda3\\envs\\ctse_env\\lib\\site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\user\\anaconda3\\envs\\ctse_env\\lib\\site-packages (from openai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in c:\\users\\user\\anaconda3\\envs\\ctse_env\\lib\\site-packages (from openai) (4.13.2)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\user\\anaconda3\\envs\\ctse_env\\lib\\site-packages (from scikit-learn) (1.15.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\user\\anaconda3\\envs\\ctse_env\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\user\\anaconda3\\envs\\ctse_env\\lib\\site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: comm>=0.1.3 in c:\\users\\user\\anaconda3\\envs\\ctse_env\\lib\\site-packages (from ipywidgets) (0.2.2)\n",
      "Requirement already satisfied: ipython>=6.1.0 in c:\\users\\user\\anaconda3\\envs\\ctse_env\\lib\\site-packages (from ipywidgets) (8.35.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in c:\\users\\user\\anaconda3\\envs\\ctse_env\\lib\\site-packages (from ipywidgets) (5.14.3)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.14 in c:\\users\\user\\anaconda3\\envs\\ctse_env\\lib\\site-packages (from ipywidgets) (4.0.14)\n",
      "Requirement already satisfied: jupyterlab_widgets~=3.0.14 in c:\\users\\user\\anaconda3\\envs\\ctse_env\\lib\\site-packages (from ipywidgets) (3.0.14)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\user\\anaconda3\\envs\\ctse_env\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\user\\anaconda3\\envs\\ctse_env\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
      "Requirement already satisfied: certifi in c:\\users\\user\\anaconda3\\envs\\ctse_env\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (2025.1.31)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\user\\anaconda3\\envs\\ctse_env\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (1.0.8)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\user\\anaconda3\\envs\\ctse_env\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\anaconda3\\envs\\ctse_env\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.4.6)\n",
      "Requirement already satisfied: decorator in c:\\users\\user\\anaconda3\\envs\\ctse_env\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (5.2.1)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\users\\user\\anaconda3\\envs\\ctse_env\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.19.2)\n",
      "Requirement already satisfied: matplotlib-inline in c:\\users\\user\\anaconda3\\envs\\ctse_env\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.1.7)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in c:\\users\\user\\anaconda3\\envs\\ctse_env\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (3.0.51)\n",
      "Requirement already satisfied: pygments>=2.4.0 in c:\\users\\user\\anaconda3\\envs\\ctse_env\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (2.19.1)\n",
      "Requirement already satisfied: stack_data in c:\\users\\user\\anaconda3\\envs\\ctse_env\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.6.3)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\user\\anaconda3\\envs\\ctse_env\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.1 in c:\\users\\user\\anaconda3\\envs\\ctse_env\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (2.33.1)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\user\\anaconda3\\envs\\ctse_env\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (0.4.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in c:\\users\\user\\anaconda3\\envs\\ctse_env\\lib\\site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.4)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\user\\anaconda3\\envs\\ctse_env\\lib\\site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets) (0.2.13)\n",
      "Requirement already satisfied: executing>=1.2.0 in c:\\users\\user\\anaconda3\\envs\\ctse_env\\lib\\site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (2.2.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in c:\\users\\user\\anaconda3\\envs\\ctse_env\\lib\\site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (3.0.0)\n",
      "Requirement already satisfied: pure-eval in c:\\users\\user\\anaconda3\\envs\\ctse_env\\lib\\site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (0.2.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install openai PyPDF2 numpy scikit-learn ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "104be24e-f779-497e-88be-29c00a589497",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: streamlit in c:\\users\\user\\anaconda3\\envs\\ctse_env\\lib\\site-packages (1.44.1)\n",
      "Requirement already satisfied: streamlit-chat in c:\\users\\user\\anaconda3\\envs\\ctse_env\\lib\\site-packages (0.1.1)\n",
      "Requirement already satisfied: altair<6,>=4.0 in c:\\users\\user\\anaconda3\\envs\\ctse_env\\lib\\site-packages (from streamlit) (5.5.0)\n",
      "Requirement already satisfied: blinker<2,>=1.0.0 in c:\\users\\user\\anaconda3\\envs\\ctse_env\\lib\\site-packages (from streamlit) (1.9.0)\n",
      "Requirement already satisfied: cachetools<6,>=4.0 in c:\\users\\user\\anaconda3\\envs\\ctse_env\\lib\\site-packages (from streamlit) (5.5.2)\n",
      "Requirement already satisfied: click<9,>=7.0 in c:\\users\\user\\anaconda3\\envs\\ctse_env\\lib\\site-packages (from streamlit) (8.1.8)\n",
      "Requirement already satisfied: numpy<3,>=1.23 in c:\\users\\user\\anaconda3\\envs\\ctse_env\\lib\\site-packages (from streamlit) (2.2.5)\n",
      "Requirement already satisfied: packaging<25,>=20 in c:\\users\\user\\anaconda3\\envs\\ctse_env\\lib\\site-packages (from streamlit) (24.2)\n",
      "Requirement already satisfied: pandas<3,>=1.4.0 in c:\\users\\user\\anaconda3\\envs\\ctse_env\\lib\\site-packages (from streamlit) (2.2.3)\n",
      "Requirement already satisfied: pillow<12,>=7.1.0 in c:\\users\\user\\anaconda3\\envs\\ctse_env\\lib\\site-packages (from streamlit) (11.2.1)\n",
      "Requirement already satisfied: protobuf<6,>=3.20 in c:\\users\\user\\anaconda3\\envs\\ctse_env\\lib\\site-packages (from streamlit) (5.29.4)\n",
      "Requirement already satisfied: pyarrow>=7.0 in c:\\users\\user\\anaconda3\\envs\\ctse_env\\lib\\site-packages (from streamlit) (20.0.0)\n",
      "Requirement already satisfied: requests<3,>=2.27 in c:\\users\\user\\anaconda3\\envs\\ctse_env\\lib\\site-packages (from streamlit) (2.32.3)\n",
      "Requirement already satisfied: tenacity<10,>=8.1.0 in c:\\users\\user\\anaconda3\\envs\\ctse_env\\lib\\site-packages (from streamlit) (9.1.2)\n",
      "Requirement already satisfied: toml<2,>=0.10.1 in c:\\users\\user\\anaconda3\\envs\\ctse_env\\lib\\site-packages (from streamlit) (0.10.2)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.4.0 in c:\\users\\user\\anaconda3\\envs\\ctse_env\\lib\\site-packages (from streamlit) (4.13.2)\n",
      "Requirement already satisfied: watchdog<7,>=2.1.5 in c:\\users\\user\\anaconda3\\envs\\ctse_env\\lib\\site-packages (from streamlit) (6.0.0)\n",
      "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in c:\\users\\user\\anaconda3\\envs\\ctse_env\\lib\\site-packages (from streamlit) (3.1.44)\n",
      "Requirement already satisfied: pydeck<1,>=0.8.0b4 in c:\\users\\user\\anaconda3\\envs\\ctse_env\\lib\\site-packages (from streamlit) (0.9.1)\n",
      "Requirement already satisfied: tornado<7,>=6.0.3 in c:\\users\\user\\anaconda3\\envs\\ctse_env\\lib\\site-packages (from streamlit) (6.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\user\\anaconda3\\envs\\ctse_env\\lib\\site-packages (from altair<6,>=4.0->streamlit) (3.1.6)\n",
      "Requirement already satisfied: jsonschema>=3.0 in c:\\users\\user\\anaconda3\\envs\\ctse_env\\lib\\site-packages (from altair<6,>=4.0->streamlit) (4.23.0)\n",
      "Requirement already satisfied: narwhals>=1.14.2 in c:\\users\\user\\anaconda3\\envs\\ctse_env\\lib\\site-packages (from altair<6,>=4.0->streamlit) (1.37.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\anaconda3\\envs\\ctse_env\\lib\\site-packages (from click<9,>=7.0->streamlit) (0.4.6)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in c:\\users\\user\\anaconda3\\envs\\ctse_env\\lib\\site-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\user\\anaconda3\\envs\\ctse_env\\lib\\site-packages (from pandas<3,>=1.4.0->streamlit) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\user\\anaconda3\\envs\\ctse_env\\lib\\site-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\user\\anaconda3\\envs\\ctse_env\\lib\\site-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages (from requests<3,>=2.27->streamlit) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\anaconda3\\envs\\ctse_env\\lib\\site-packages (from requests<3,>=2.27->streamlit) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\user\\anaconda3\\envs\\ctse_env\\lib\\site-packages (from requests<3,>=2.27->streamlit) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\anaconda3\\envs\\ctse_env\\lib\\site-packages (from requests<3,>=2.27->streamlit) (2025.1.31)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in c:\\users\\user\\anaconda3\\envs\\ctse_env\\lib\\site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\user\\anaconda3\\envs\\ctse_env\\lib\\site-packages (from jinja2->altair<6,>=4.0->streamlit) (3.0.2)\n",
      "Requirement already satisfied: attrs>=22.2.0 in c:\\users\\user\\anaconda3\\envs\\ctse_env\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (25.3.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\users\\user\\anaconda3\\envs\\ctse_env\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2025.4.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\users\\user\\anaconda3\\envs\\ctse_env\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\users\\user\\anaconda3\\envs\\ctse_env\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.24.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\user\\anaconda3\\envs\\ctse_env\\lib\\site-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install  streamlit streamlit-chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0575a31a-af17-474e-984d-57bb6f296a4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-pptx in c:\\users\\user\\anaconda3\\envs\\ctse_env\\lib\\site-packages (1.0.2)\n",
      "Requirement already satisfied: Pillow>=3.3.2 in c:\\users\\user\\anaconda3\\envs\\ctse_env\\lib\\site-packages (from python-pptx) (11.2.1)\n",
      "Requirement already satisfied: XlsxWriter>=0.5.7 in c:\\users\\user\\anaconda3\\envs\\ctse_env\\lib\\site-packages (from python-pptx) (3.2.3)\n",
      "Requirement already satisfied: lxml>=3.1.0 in c:\\users\\user\\anaconda3\\envs\\ctse_env\\lib\\site-packages (from python-pptx) (5.4.0)\n",
      "Requirement already satisfied: typing-extensions>=4.9.0 in c:\\users\\user\\anaconda3\\envs\\ctse_env\\lib\\site-packages (from python-pptx) (4.13.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install python-pptx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6d76784a-704f-4071-bcd0-556a3bf6fe06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: streamlit in c:\\users\\user\\anaconda3\\envs\\ctse_env\\lib\\site-packages (1.44.1)\n",
      "Requirement already satisfied: streamlit-chat in c:\\users\\user\\anaconda3\\envs\\ctse_env\\lib\\site-packages (0.1.1)\n",
      "Requirement already satisfied: langchain in c:\\users\\user\\anaconda3\\envs\\ctse_env\\lib\\site-packages (0.3.24)\n",
      "Requirement already satisfied: langchain-openai in c:\\users\\user\\anaconda3\\envs\\ctse_env\\lib\\site-packages (0.3.14)\n",
      "Requirement already satisfied: openai in c:\\users\\user\\anaconda3\\envs\\ctse_env\\lib\\site-packages (1.76.0)\n",
      "Requirement already satisfied: PyPDF2 in c:\\users\\user\\anaconda3\\envs\\ctse_env\\lib\\site-packages (3.0.1)\n",
      "Requirement already satisfied: python-pptx in c:\\users\\user\\anaconda3\\envs\\ctse_env\\lib\\site-packages (1.0.2)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\user\\anaconda3\\envs\\ctse_env\\lib\\site-packages (1.6.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\user\\anaconda3\\envs\\ctse_env\\lib\\site-packages (2.2.5)\n",
      "Requirement already satisfied: altair<6,>=4.0 in c:\\users\\user\\anaconda3\\envs\\ctse_env\\lib\\site-packages (from streamlit) (5.5.0)\n",
      "Requirement already satisfied: blinker<2,>=1.0.0 in c:\\users\\user\\anaconda3\\envs\\ctse_env\\lib\\site-packages (from streamlit) (1.9.0)\n",
      "Requirement already satisfied: cachetools<6,>=4.0 in c:\\users\\user\\anaconda3\\envs\\ctse_env\\lib\\site-packages (from streamlit) (5.5.2)\n",
      "Requirement already satisfied: click<9,>=7.0 in c:\\users\\user\\anaconda3\\envs\\ctse_env\\lib\\site-packages (from streamlit) (8.1.8)\n",
      "Requirement already satisfied: packaging<25,>=20 in c:\\users\\user\\anaconda3\\envs\\ctse_env\\lib\\site-packages (from streamlit) (24.2)\n",
      "Requirement already satisfied: pandas<3,>=1.4.0 in c:\\users\\user\\anaconda3\\envs\\ctse_env\\lib\\site-packages (from streamlit) (2.2.3)\n",
      "Requirement already satisfied: pillow<12,>=7.1.0 in c:\\users\\user\\anaconda3\\envs\\ctse_env\\lib\\site-packages (from streamlit) (11.2.1)\n",
      "Requirement already satisfied: protobuf<6,>=3.20 in c:\\users\\user\\anaconda3\\envs\\ctse_env\\lib\\site-packages (from streamlit) (5.29.4)\n",
      "Requirement already satisfied: pyarrow>=7.0 in c:\\users\\user\\anaconda3\\envs\\ctse_env\\lib\\site-packages (from streamlit) (20.0.0)\n",
      "Requirement already satisfied: requests<3,>=2.27 in c:\\users\\user\\anaconda3\\envs\\ctse_env\\lib\\site-packages (from streamlit) (2.32.3)\n",
      "Requirement already satisfied: tenacity<10,>=8.1.0 in c:\\users\\user\\anaconda3\\envs\\ctse_env\\lib\\site-packages (from streamlit) (9.1.2)\n",
      "Requirement already satisfied: toml<2,>=0.10.1 in c:\\users\\user\\anaconda3\\envs\\ctse_env\\lib\\site-packages (from streamlit) (0.10.2)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.4.0 in c:\\users\\user\\anaconda3\\envs\\ctse_env\\lib\\site-packages (from streamlit) (4.13.2)\n",
      "Requirement already satisfied: watchdog<7,>=2.1.5 in c:\\users\\user\\anaconda3\\envs\\ctse_env\\lib\\site-packages (from streamlit) (6.0.0)\n",
      "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in c:\\users\\user\\anaconda3\\envs\\ctse_env\\lib\\site-packages (from streamlit) (3.1.44)\n",
      "Requirement already satisfied: pydeck<1,>=0.8.0b4 in c:\\users\\user\\anaconda3\\envs\\ctse_env\\lib\\site-packages (from streamlit) (0.9.1)\n",
      "Requirement already satisfied: tornado<7,>=6.0.3 in c:\\users\\user\\anaconda3\\envs\\ctse_env\\lib\\site-packages (from streamlit) (6.4.2)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.55 in c:\\users\\user\\anaconda3\\envs\\ctse_env\\lib\\site-packages (from langchain) (0.3.55)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in c:\\users\\user\\anaconda3\\envs\\ctse_env\\lib\\site-packages (from langchain) (0.3.8)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.17 in c:\\users\\user\\anaconda3\\envs\\ctse_env\\lib\\site-packages (from langchain) (0.3.33)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\user\\anaconda3\\envs\\ctse_env\\lib\\site-packages (from langchain) (2.11.3)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\user\\anaconda3\\envs\\ctse_env\\lib\\site-packages (from langchain) (2.0.40)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\user\\anaconda3\\envs\\ctse_env\\lib\\site-packages (from langchain) (6.0.2)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in c:\\users\\user\\anaconda3\\envs\\ctse_env\\lib\\site-packages (from langchain) (4.0.3)\n",
      "Requirement already satisfied: tiktoken<1,>=0.7 in c:\\users\\user\\anaconda3\\envs\\ctse_env\\lib\\site-packages (from langchain-openai) (0.9.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\user\\anaconda3\\envs\\ctse_env\\lib\\site-packages (from openai) (4.9.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\user\\anaconda3\\envs\\ctse_env\\lib\\site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\user\\anaconda3\\envs\\ctse_env\\lib\\site-packages (from openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\user\\anaconda3\\envs\\ctse_env\\lib\\site-packages (from openai) (0.9.0)\n",
      "Requirement already satisfied: sniffio in c:\\users\\user\\anaconda3\\envs\\ctse_env\\lib\\site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\user\\anaconda3\\envs\\ctse_env\\lib\\site-packages (from openai) (4.67.1)\n",
      "Requirement already satisfied: XlsxWriter>=0.5.7 in c:\\users\\user\\anaconda3\\envs\\ctse_env\\lib\\site-packages (from python-pptx) (3.2.3)\n",
      "Requirement already satisfied: lxml>=3.1.0 in c:\\users\\user\\anaconda3\\envs\\ctse_env\\lib\\site-packages (from python-pptx) (5.4.0)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\user\\anaconda3\\envs\\ctse_env\\lib\\site-packages (from scikit-learn) (1.15.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\user\\anaconda3\\envs\\ctse_env\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\user\\anaconda3\\envs\\ctse_env\\lib\\site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\user\\anaconda3\\envs\\ctse_env\\lib\\site-packages (from altair<6,>=4.0->streamlit) (3.1.6)\n",
      "Requirement already satisfied: jsonschema>=3.0 in c:\\users\\user\\anaconda3\\envs\\ctse_env\\lib\\site-packages (from altair<6,>=4.0->streamlit) (4.23.0)\n",
      "Requirement already satisfied: narwhals>=1.14.2 in c:\\users\\user\\anaconda3\\envs\\ctse_env\\lib\\site-packages (from altair<6,>=4.0->streamlit) (1.37.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\user\\anaconda3\\envs\\ctse_env\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\user\\anaconda3\\envs\\ctse_env\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\anaconda3\\envs\\ctse_env\\lib\\site-packages (from click<9,>=7.0->streamlit) (0.4.6)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in c:\\users\\user\\anaconda3\\envs\\ctse_env\\lib\\site-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
      "Requirement already satisfied: certifi in c:\\users\\user\\anaconda3\\envs\\ctse_env\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (2025.1.31)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\user\\anaconda3\\envs\\ctse_env\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (1.0.8)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\user\\anaconda3\\envs\\ctse_env\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\user\\anaconda3\\envs\\ctse_env\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.55->langchain) (1.33)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\user\\anaconda3\\envs\\ctse_env\\lib\\site-packages (from langsmith<0.4,>=0.1.17->langchain) (3.10.16)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\user\\anaconda3\\envs\\ctse_env\\lib\\site-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in c:\\users\\user\\anaconda3\\envs\\ctse_env\\lib\\site-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\user\\anaconda3\\envs\\ctse_env\\lib\\site-packages (from pandas<3,>=1.4.0->streamlit) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\user\\anaconda3\\envs\\ctse_env\\lib\\site-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\user\\anaconda3\\envs\\ctse_env\\lib\\site-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\user\\anaconda3\\envs\\ctse_env\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.1 in c:\\users\\user\\anaconda3\\envs\\ctse_env\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.1)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\user\\anaconda3\\envs\\ctse_env\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages (from requests<3,>=2.27->streamlit) (3.1.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\user\\anaconda3\\envs\\ctse_env\\lib\\site-packages (from requests<3,>=2.27->streamlit) (2.4.0)\n",
      "Requirement already satisfied: greenlet>=1 in c:\\users\\user\\anaconda3\\envs\\ctse_env\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.1)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\user\\anaconda3\\envs\\ctse_env\\lib\\site-packages (from tiktoken<1,>=0.7->langchain-openai) (2024.11.6)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in c:\\users\\user\\anaconda3\\envs\\ctse_env\\lib\\site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\user\\anaconda3\\envs\\ctse_env\\lib\\site-packages (from jinja2->altair<6,>=4.0->streamlit) (3.0.2)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\user\\anaconda3\\envs\\ctse_env\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.55->langchain) (3.0.0)\n",
      "Requirement already satisfied: attrs>=22.2.0 in c:\\users\\user\\anaconda3\\envs\\ctse_env\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (25.3.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\users\\user\\anaconda3\\envs\\ctse_env\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2025.4.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\users\\user\\anaconda3\\envs\\ctse_env\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\users\\user\\anaconda3\\envs\\ctse_env\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.24.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\user\\anaconda3\\envs\\ctse_env\\lib\\site-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install streamlit streamlit-chat langchain langchain-openai openai PyPDF2 python-pptx scikit-learn numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b04fb3da-0f80-45a1-9bf6-6a7fcc6ae6d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-29 15:46:25.201 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
     ]
    }
   ],
   "source": [
    "# This chatbot answers questions based on CTSE lecture notes using OpenRouter's LLM API.\n",
    "import os\n",
    "import openai\n",
    "from PyPDF2 import PdfReader\n",
    "from typing import List\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, Markdown, clear_output\n",
    "import streamlit as st\n",
    "from streamlit_chat import message\n",
    "from pptx import Presentation  # For PowerPoint files\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "from langchain_core.chat_history import InMemoryChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f85c079e-14cd-45f1-b8b3-76d6e51d9a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "class Config:\n",
    "    OPENROUTER_API_KEY = os.getenv(\"OPENROUTER_API_KEY\", \"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\")\n",
    "    OPENROUTER_BASE_URL = \"https://openrouter.ai/api/v1\" # Replace with your actual API key\n",
    "   # OPENROUTER_BASE_URL = \"https://openrouter.ai/api/v1\"\n",
    "    MODEL_NAME = \"mistralai/mistral-7b-instruct\"  # Cost-effective model\n",
    "    TEMPERATURE = 0.3  # Controls randomness of responses\n",
    "    MAX_TOKENS = 1000  # Limit response length\n",
    "    CONTEXT_TOKENS = 3000  # Max context to send to LLM\n",
    "    CHUNK_SIZE = 500  # Size of text chunks for processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "484549f3-7a47-4a91-bbd2-1b78c264928a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize OpenAI client for OpenRouter\n",
    "client = openai.OpenAI(\n",
    "    base_url=Config.OPENROUTER_BASE_URL,\n",
    "    api_key=Config.OPENROUTER_API_KEY,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3b1c2f2e-5597-4af7-8ed9-a451119dd0ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Document Processing Functions\n",
    "def extract_text_from_pdf(pdf_path: str) -> str:\n",
    "    \"\"\"Extract text from a PDF file\"\"\"\n",
    "    text = \"\"\n",
    "    try:\n",
    "        with open(pdf_path, \"rb\") as file:\n",
    "            reader = PdfReader(file)\n",
    "            for page in reader.pages:\n",
    "                text += page.extract_text() or \"\"  # Handle None returns\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading PDF {pdf_path}: {str(e)}\")\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ebddf5f7-17a6-41b6-b021-f368c5f43a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#new\n",
    "def extract_text_from_pptx(pptx_path: str) -> str:\n",
    "    \"\"\"Extract text from a PowerPoint file\"\"\"\n",
    "    text = \"\"\n",
    "    try:\n",
    "        prs = Presentation(pptx_path)\n",
    "        for slide in prs.slides:\n",
    "            for shape in slide.shapes:\n",
    "                if hasattr(shape, \"text\"):\n",
    "                    text += shape.text + \"\\n\"\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading PPTX {pptx_path}: {str(e)}\")\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "71af6414-d4f2-488b-8517-4130dc2a1a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_text(text: str, chunk_size: int = Config.CHUNK_SIZE) -> List[str]:\n",
    "    \"\"\"Split text into manageable chunks\"\"\"\n",
    "    words = text.split()\n",
    "    chunks = [' '.join(words[i:i + chunk_size]) for i in range(0, len(words), chunk_size)]\n",
    "    return chunks\n",
    "\n",
    "def create_vector_index(text_chunks: List[str]):\n",
    "    \"\"\"Create TF-IDF vector index for semantic search\"\"\"\n",
    "    vectorizer = TfidfVectorizer(stop_words='english')\n",
    "    tfidf_matrix = vectorizer.fit_transform(text_chunks)\n",
    "    return vectorizer, tfidf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6425268e-6e26-4632-96c9-9f0c5888c792",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Knowledge Base Class\n",
    "class LectureNotesKB:\n",
    "    def __init__(self):\n",
    "        self.notes = {}\n",
    "        self.vectorizers = {}\n",
    "        self.tfidf_matrices = {}\n",
    "        self.chunks = {}\n",
    "    \n",
    "    def add_lecture(self, lecture_name: str, file_path: str):\n",
    "        \"\"\"Add a lecture to the knowledge base from a PDF or PPTX\"\"\"\n",
    "        text = \"\"\n",
    "        if file_path.lower().endswith(\".pdf\"):\n",
    "            text = extract_text_from_pdf(file_path)\n",
    "        elif file_path.lower().endswith(\".pptx\"):\n",
    "            text = extract_text_from_pptx(file_path)\n",
    "        else:\n",
    "            print(f\"Unsupported file type for {file_path}\")\n",
    "            return\n",
    "        \n",
    "        if not text:\n",
    "            print(f\"Warning: No text extracted from {file_path}\")\n",
    "            return\n",
    "            \n",
    "        chunks = chunk_text(text)\n",
    "        vectorizer, tfidf_matrix = create_vector_index(chunks)\n",
    "        \n",
    "        self.notes[lecture_name] = text\n",
    "        self.chunks[lecture_name] = chunks\n",
    "        self.vectorizers[lecture_name] = vectorizer\n",
    "        self.tfidf_matrices[lecture_name] = tfidf_matrix\n",
    "        print(f\"Loaded lecture: {lecture_name} ({len(chunks)} chunks)\")\n",
    "     \n",
    "    def get_relevant_chunks(self, lecture_name: str, query: str, top_k: int = 3) -> List[str]:\n",
    "        \"\"\"Retrieve most relevant text chunks for a query\"\"\"\n",
    "        if lecture_name not in self.notes:\n",
    "            print(f\"Lecture {lecture_name} not found in knowledge base\")\n",
    "            return []\n",
    "            \n",
    "        vectorizer = self.vectorizers[lecture_name]\n",
    "        tfidf_matrix = self.tfidf_matrices[lecture_name]\n",
    "        \n",
    "        query_vec = vectorizer.transform([query])\n",
    "        similarities = cosine_similarity(query_vec, tfidf_matrix).flatten()\n",
    "        top_indices = similarities.argsort()[-top_k:][::-1]\n",
    "        \n",
    "        return [self.chunks[lecture_name][i] for i in top_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "968dcce4-b00d-4fc9-8dcd-9c01ccfb79fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chatbot Class with LangChain\n",
    "class LectureChatbot:\n",
    "    def __init__(self):\n",
    "        self.knowledge_base = LectureNotesKB()\n",
    "        # Initialize LangChain LLM\n",
    "        self.llm = ChatOpenAI(\n",
    "            model=Config.MODEL_NAME,\n",
    "            openai_api_key=Config.OPENROUTER_API_KEY,\n",
    "            openai_api_base=Config.OPENROUTER_BASE_URL,\n",
    "            temperature=Config.TEMPERATURE,\n",
    "            max_tokens=Config.MAX_TOKENS\n",
    "        )\n",
    "        # Define prompt template\n",
    "        self.prompt = ChatPromptTemplate.from_messages([\n",
    "            (\"system\", \"\"\"You are an expert teaching assistant for the CTSE course. \n",
    "Answer the student's question based strictly on the provided lecture notes context.\n",
    "If the answer isn't in the notes, say \"I don't have that information in my lecture notes.\"\n",
    "\n",
    "Lecture Context:\n",
    "{context}\"\"\"),\n",
    "            MessagesPlaceholder(variable_name=\"history\"),\n",
    "            (\"human\", \"{input}\")\n",
    "        ])\n",
    "        # Initialize chat history store\n",
    "        self.chat_histories = {}\n",
    "        # Create runnable chain\n",
    "        self.chain = (\n",
    "            RunnablePassthrough.assign(\n",
    "                context=lambda x: \"\\n\\n\".join(\n",
    "                    self.knowledge_base.get_relevant_chunks(x[\"lecture_name\"], x[\"input\"])\n",
    "                )[:Config.CONTEXT_TOKENS]\n",
    "            )\n",
    "            | self.prompt\n",
    "            | self.llm\n",
    "        )\n",
    "        # Wrap with message history\n",
    "        self.runnable = RunnableWithMessageHistory(\n",
    "            self.chain,\n",
    "            lambda session_id: self.get_chat_history(session_id),\n",
    "            input_messages_key=\"input\",\n",
    "            history_messages_key=\"history\"\n",
    "        )\n",
    "\n",
    "    def get_chat_history(self, session_id: str) -> InMemoryChatMessageHistory:\n",
    "        \"\"\"Get or create chat history for a session\"\"\"\n",
    "        if session_id not in self.chat_histories:\n",
    "            self.chat_histories[session_id] = InMemoryChatMessageHistory()\n",
    "        return self.chat_histories[session_id]\n",
    "\n",
    "    def load_lecture(self, lecture_name: str, file_path: str):\n",
    "        \"\"\"Load lecture notes (PDF or PPTX) into the knowledge base\"\"\"\n",
    "        self.knowledge_base.add_lecture(lecture_name, file_path)\n",
    "\n",
    "    def generate_response(self, lecture_name: str, question: str, session_id: str) -> str:\n",
    "        \"\"\"Generate a response to the user's question\"\"\"\n",
    "        try:\n",
    "            response = self.runnable.invoke(\n",
    "                {\"input\": question, \"lecture_name\": lecture_name},\n",
    "                config={\"configurable\": {\"session_id\": session_id}}\n",
    "            )\n",
    "            return response.content\n",
    "        except Exception as e:\n",
    "            return f\"Error generating response: {str(e)}\"\n",
    "\n",
    "    def clear_history(self, session_id: str):\n",
    "        \"\"\"Clear chat history for a session\"\"\"\n",
    "        if session_id in self.chat_histories:\n",
    "            self.chat_histories[session_id] = InMemoryChatMessageHistory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bdab369b-7e58-49a9-b09d-e91e29323ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "# UI Components\n",
    "#def create_chat_interface(chatbot: LectureChatbot, lecture_name: str):\n",
    "#    \"\"\"Create interactive chat interface\"\"\"\n",
    "#    output = widgets.Output()\n",
    "#    question_input = widgets.Text(\n",
    "#        placeholder='Ask a question about the lecture...',\n",
    "#        layout=widgets.Layout(width='80%')\n",
    "#    )\n",
    "    \n",
    "#    def on_submit(_):\n",
    "#        with output:\n",
    "#            question = question_input.value\n",
    "#            if question.strip():\n",
    "#               display(Markdown(f\"**You:** {question}\"))\n",
    "#                answer = chatbot.generate_response(lecture_name, question)\n",
    "#                display(Markdown(f\"**Assistant:** {answer}\"))\n",
    "#                question_input.value = ''\n",
    "    \n",
    "#    submit_button = widgets.Button(description=\"Ask\", layout=widgets.Layout(width='20%'))\n",
    "#    submit_button.on_click(on_submit)\n",
    "    \n",
    "#    input_box = widgets.HBox([question_input, submit_button])\n",
    "#    display(widgets.VBox([output, input_box]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "061b0037-fea7-49c7-83f1-6d461dc96818",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Streamlit Web Interface\n",
    "def main():\n",
    "    st.set_page_config(page_title=\"CTSE Lecture Chatbot\", page_icon=\"📚\", layout=\"wide\")\n",
    "    st.title(\"CTSE Lecture Chatbot\")\n",
    "    \n",
    "    chatbot = LectureChatbot()\n",
    "    LECTURE_NOTES_DIR = \"ctse_lecture_notes\"\n",
    "    os.makedirs(LECTURE_NOTES_DIR, exist_ok=True)\n",
    "    \n",
    "    # File upload\n",
    "    uploaded_file = st.file_uploader(\"Upload a PDF or PPTX lecture\", type=[\"pdf\", \"pptx\"])\n",
    "    if uploaded_file:\n",
    "        file_path = os.path.join(LECTURE_NOTES_DIR, uploaded_file.name)\n",
    "        with open(file_path, \"wb\") as f:\n",
    "            f.write(uploaded_file.getbuffer())\n",
    "        chatbot.load_lecture(uploaded_file.name.split('.')[0].title(), file_path)\n",
    "        st.success(f\"Uploaded and loaded: {uploaded_file.name}\")\n",
    "    \n",
    "    # Scan directory for PDF and PPTX files\n",
    "    available_lectures = {}\n",
    "    try:\n",
    "        for file in os.listdir(LECTURE_NOTES_DIR):\n",
    "            if file.lower().endswith(('.pdf', '.pptx')):\n",
    "                lecture_name = os.path.splitext(file)[0].replace('_', ' ').title()\n",
    "                available_lectures[lecture_name] = os.path.join(LECTURE_NOTES_DIR, file)\n",
    "                \n",
    "        if not available_lectures:\n",
    "            st.error(f\"No PDF or PPTX files found in {LECTURE_NOTES_DIR}. Please upload or add lecture files.\")\n",
    "            return\n",
    "            \n",
    "        # Load available lectures\n",
    "        for name, path in available_lectures.items():\n",
    "            if name not in chatbot.knowledge_base.notes:\n",
    "                chatbot.load_lecture(name, path)\n",
    "        \n",
    "        # Lecture selection\n",
    "        lecture_name = st.selectbox(\"Select Lecture:\", list(available_lectures.keys()), key=\"lecture_select\")\n",
    "        \n",
    "        # Initialize session state for chat history\n",
    "        if \"messages\" not in st.session_state:\n",
    "            st.session_state.messages = []\n",
    "        \n",
    "        # Session ID for chat history\n",
    "        session_id = f\"{lecture_name}_session\"\n",
    "        \n",
    "        # Clear chat button\n",
    "        if st.button(\"Clear Chat\"):\n",
    "            st.session_state.messages = []\n",
    "            chatbot.clear_history(session_id)\n",
    "            st.rerun()\n",
    "        \n",
    "        # Display chat history\n",
    "        for idx, msg in enumerate(st.session_state.messages):\n",
    "            if msg[\"lecture\"] == lecture_name:\n",
    "                message(msg[\"content\"], is_user=(msg[\"role\"] == \"user\"), key=f\"msg_{idx}\")\n",
    "        \n",
    "        # Input form for question\n",
    "        with st.form(key=\"question_form\", clear_on_submit=True):\n",
    "            question = st.text_input(\"Ask a question about the lecture...\", key=\"question_input\")\n",
    "            submit_button = st.form_submit_button(\"Ask\")\n",
    "            \n",
    "            if submit_button and question.strip():\n",
    "                # Add user message\n",
    "                st.session_state.messages.append({\"role\": \"user\", \"content\": question, \"lecture\": lecture_name})\n",
    "                # Generate response\n",
    "                answer = chatbot.generate_response(lecture_name, question, session_id)\n",
    "                # Add assistant response\n",
    "                st.session_state.messages.append({\"role\": \"assistant\", \"content\": answer, \"lecture\": lecture_name})\n",
    "                # Rerun to update UI\n",
    "                st.rerun()\n",
    "                \n",
    "    except Exception as e:\n",
    "        st.error(f\"Error loading lectures from {LECTURE_NOTES_DIR}: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "698a098f-62e9-4642-87dc-f15eb7f54397",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-29 15:46:50.591 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-29 15:46:50.593 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-29 15:46:50.789 \n",
      "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
      "  command:\n",
      "\n",
      "    streamlit run C:\\Users\\USER\\anaconda3\\envs\\ctse_env\\lib\\site-packages\\ipykernel_launcher.py [ARGUMENTS]\n",
      "2025-04-29 15:46:50.790 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-29 15:46:51.518 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-29 15:46:51.519 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-29 15:46:51.521 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-29 15:46:51.522 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-29 15:46:51.523 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded lecture: Aws User Groups Colombo - Introduction To Aws Cloud Platform (2 chunks)\n",
      "Loaded lecture: Cap Theorem (1 chunks)\n",
      "Loaded lecture: Cloud Computing 101 (2 chunks)\n",
      "Loaded lecture: Introduction To Microservices (2 chunks)\n",
      "Loaded lecture: Key Essentials For Building Application In Cloud (4 chunks)\n",
      "Loaded lecture: Lecture 1 (2 chunks)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-29 15:46:54.164 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-29 15:46:54.166 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-29 15:46:54.167 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-29 15:46:54.169 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-29 15:46:54.170 Session state does not function when running a script without `streamlit run`\n",
      "2025-04-29 15:46:54.171 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-29 15:46:54.172 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-29 15:46:54.173 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-29 15:46:54.174 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-29 15:46:54.175 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-29 15:46:54.176 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-29 15:46:54.178 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-29 15:46:54.179 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-29 15:46:54.181 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-29 15:46:54.181 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-29 15:46:54.184 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-29 15:46:54.185 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-29 15:46:54.186 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-29 15:46:54.187 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-29 15:46:54.188 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-29 15:46:54.190 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-29 15:46:54.191 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-29 15:46:54.192 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-29 15:46:54.193 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-29 15:46:54.194 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-29 15:46:54.196 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-29 15:46:54.197 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-29 15:46:54.199 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-29 15:46:54.202 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded lecture: Lecture 2 (5 chunks)\n",
      "Loaded lecture: Microservice Design Patterns (3 chunks)\n"
     ]
    }
   ],
   "source": [
    "# Run the chatbot\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aebd51b2-4efe-43f5-acb5-5a75a27fdbd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting app.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile app.py\n",
    "# This chatbot answers questions based on CTSE lecture notes using OpenRouter's LLM API.\n",
    "import os\n",
    "import openai\n",
    "from PyPDF2 import PdfReader\n",
    "from typing import List\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, Markdown, clear_output\n",
    "import streamlit as st\n",
    "from streamlit_chat import message\n",
    "from pptx import Presentation  # For PowerPoint files\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "from langchain_core.chat_history import InMemoryChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "\n",
    "# Configuration\n",
    "class Config:\n",
    "    OPENROUTER_API_KEY = os.getenv(\"OPENROUTER_API_KEY\", \"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\")\n",
    "    OPENROUTER_BASE_URL = \"https://openrouter.ai/api/v1\" # Replace with your actual API key\n",
    "   # OPENROUTER_BASE_URL = \"https://openrouter.ai/api/v1\"\n",
    "    MODEL_NAME = \"mistralai/mistral-7b-instruct\"  # Cost-effective model\n",
    "    TEMPERATURE = 0.3  # Controls randomness of responses\n",
    "    MAX_TOKENS = 1000  # Limit response length\n",
    "    CONTEXT_TOKENS = 3000  # Max context to send to LLM\n",
    "    CHUNK_SIZE = 500  # Size of text chunks for processing\n",
    "# Initialize OpenAI client for OpenRouter\n",
    "client = openai.OpenAI(\n",
    "    base_url=Config.OPENROUTER_BASE_URL,\n",
    "    api_key=Config.OPENROUTER_API_KEY,\n",
    ")\n",
    "\n",
    "# Document Processing Functions\n",
    "def extract_text_from_pdf(pdf_path: str) -> str:\n",
    "    \"\"\"Extract text from a PDF file\"\"\"\n",
    "    text = \"\"\n",
    "    try:\n",
    "        with open(pdf_path, \"rb\") as file:\n",
    "            reader = PdfReader(file)\n",
    "            for page in reader.pages:\n",
    "                text += page.extract_text() or \"\"  # Handle None returns\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading PDF {pdf_path}: {str(e)}\")\n",
    "    return text\n",
    "#new\n",
    "def extract_text_from_pptx(pptx_path: str) -> str:\n",
    "    \"\"\"Extract text from a PowerPoint file\"\"\"\n",
    "    text = \"\"\n",
    "    try:\n",
    "        prs = Presentation(pptx_path)\n",
    "        for slide in prs.slides:\n",
    "            for shape in slide.shapes:\n",
    "                if hasattr(shape, \"text\"):\n",
    "                    text += shape.text + \"\\n\"\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading PPTX {pptx_path}: {str(e)}\")\n",
    "    return text\n",
    "\n",
    "def chunk_text(text: str, chunk_size: int = Config.CHUNK_SIZE) -> List[str]:\n",
    "    \"\"\"Split text into manageable chunks\"\"\"\n",
    "    words = text.split()\n",
    "    chunks = [' '.join(words[i:i + chunk_size]) for i in range(0, len(words), chunk_size)]\n",
    "    return chunks\n",
    "\n",
    "def create_vector_index(text_chunks: List[str]):\n",
    "    \"\"\"Create TF-IDF vector index for semantic search\"\"\"\n",
    "    vectorizer = TfidfVectorizer(stop_words='english')\n",
    "    tfidf_matrix = vectorizer.fit_transform(text_chunks)\n",
    "    return vectorizer, tfidf_matrix\n",
    "\n",
    "# Knowledge Base Class\n",
    "class LectureNotesKB:\n",
    "    def __init__(self):\n",
    "        self.notes = {}\n",
    "        self.vectorizers = {}\n",
    "        self.tfidf_matrices = {}\n",
    "        self.chunks = {}\n",
    "    \n",
    "    def add_lecture(self, lecture_name: str, file_path: str):\n",
    "        \"\"\"Add a lecture to the knowledge base from a PDF or PPTX\"\"\"\n",
    "        text = \"\"\n",
    "        if file_path.lower().endswith(\".pdf\"):\n",
    "            text = extract_text_from_pdf(file_path)\n",
    "        elif file_path.lower().endswith(\".pptx\"):\n",
    "            text = extract_text_from_pptx(file_path)\n",
    "        else:\n",
    "            print(f\"Unsupported file type for {file_path}\")\n",
    "            return\n",
    "        \n",
    "        if not text:\n",
    "            print(f\"Warning: No text extracted from {file_path}\")\n",
    "            return\n",
    "            \n",
    "        chunks = chunk_text(text)\n",
    "        vectorizer, tfidf_matrix = create_vector_index(chunks)\n",
    "        \n",
    "        self.notes[lecture_name] = text\n",
    "        self.chunks[lecture_name] = chunks\n",
    "        self.vectorizers[lecture_name] = vectorizer\n",
    "        self.tfidf_matrices[lecture_name] = tfidf_matrix\n",
    "        print(f\"Loaded lecture: {lecture_name} ({len(chunks)} chunks)\")\n",
    "     \n",
    "    def get_relevant_chunks(self, lecture_name: str, query: str, top_k: int = 3) -> List[str]:\n",
    "        \"\"\"Retrieve most relevant text chunks for a query\"\"\"\n",
    "        if lecture_name not in self.notes:\n",
    "            print(f\"Lecture {lecture_name} not found in knowledge base\")\n",
    "            return []\n",
    "            \n",
    "        vectorizer = self.vectorizers[lecture_name]\n",
    "        tfidf_matrix = self.tfidf_matrices[lecture_name]\n",
    "        \n",
    "        query_vec = vectorizer.transform([query])\n",
    "        similarities = cosine_similarity(query_vec, tfidf_matrix).flatten()\n",
    "        top_indices = similarities.argsort()[-top_k:][::-1]\n",
    "        \n",
    "        return [self.chunks[lecture_name][i] for i in top_indices]\n",
    "# Chatbot Class with LangChain\n",
    "class LectureChatbot:\n",
    "    def __init__(self):\n",
    "        self.knowledge_base = LectureNotesKB()\n",
    "        # Initialize LangChain LLM\n",
    "        self.llm = ChatOpenAI(\n",
    "            model=Config.MODEL_NAME,\n",
    "            openai_api_key=Config.OPENROUTER_API_KEY,\n",
    "            openai_api_base=Config.OPENROUTER_BASE_URL,\n",
    "            temperature=Config.TEMPERATURE,\n",
    "            max_tokens=Config.MAX_TOKENS\n",
    "        )\n",
    "        # Define prompt template\n",
    "        self.prompt = ChatPromptTemplate.from_messages([\n",
    "            (\"system\", \"\"\"You are an expert teaching assistant for the CTSE course. \n",
    "Answer the student's question based strictly on the provided lecture notes context.\n",
    "If the answer isn't in the notes, say \"I don't have that information in my lecture notes.\"\n",
    "\n",
    "Lecture Context:\n",
    "{context}\"\"\"),\n",
    "            MessagesPlaceholder(variable_name=\"history\"),\n",
    "            (\"human\", \"{input}\")\n",
    "        ])\n",
    "        # Initialize chat history store\n",
    "        self.chat_histories = {}\n",
    "        # Create runnable chain\n",
    "        self.chain = (\n",
    "            RunnablePassthrough.assign(\n",
    "                context=lambda x: \"\\n\\n\".join(\n",
    "                    self.knowledge_base.get_relevant_chunks(x[\"lecture_name\"], x[\"input\"])\n",
    "                )[:Config.CONTEXT_TOKENS]\n",
    "            )\n",
    "            | self.prompt\n",
    "            | self.llm\n",
    "        )\n",
    "        # Wrap with message history\n",
    "        self.runnable = RunnableWithMessageHistory(\n",
    "            self.chain,\n",
    "            lambda session_id: self.get_chat_history(session_id),\n",
    "            input_messages_key=\"input\",\n",
    "            history_messages_key=\"history\"\n",
    "        )\n",
    "\n",
    "    def get_chat_history(self, session_id: str) -> InMemoryChatMessageHistory:\n",
    "        \"\"\"Get or create chat history for a session\"\"\"\n",
    "        if session_id not in self.chat_histories:\n",
    "            self.chat_histories[session_id] = InMemoryChatMessageHistory()\n",
    "        return self.chat_histories[session_id]\n",
    "\n",
    "    def load_lecture(self, lecture_name: str, file_path: str):\n",
    "        \"\"\"Load lecture notes (PDF or PPTX) into the knowledge base\"\"\"\n",
    "        self.knowledge_base.add_lecture(lecture_name, file_path)\n",
    "\n",
    "    def generate_response(self, lecture_name: str, question: str, session_id: str) -> str:\n",
    "        \"\"\"Generate a response to the user's question\"\"\"\n",
    "        try:\n",
    "            response = self.runnable.invoke(\n",
    "                {\"input\": question, \"lecture_name\": lecture_name},\n",
    "                config={\"configurable\": {\"session_id\": session_id}}\n",
    "            )\n",
    "            return response.content\n",
    "        except Exception as e:\n",
    "            return f\"Error generating response: {str(e)}\"\n",
    "\n",
    "    def clear_history(self, session_id: str):\n",
    "        \"\"\"Clear chat history for a session\"\"\"\n",
    "        if session_id in self.chat_histories:\n",
    "            self.chat_histories[session_id] = InMemoryChatMessageHistory()\n",
    "\n",
    "# Streamlit Web Interface\n",
    "def main():\n",
    "    st.set_page_config(page_title=\"CTSE Lecture Chatbot\", page_icon=\"📚\", layout=\"wide\")\n",
    "    st.title(\"CTSE Lecture Chatbot\")\n",
    "    \n",
    "    chatbot = LectureChatbot()\n",
    "    LECTURE_NOTES_DIR = \"ctse_lecture_notes\"\n",
    "    os.makedirs(LECTURE_NOTES_DIR, exist_ok=True)\n",
    "    \n",
    "    # File upload\n",
    "    uploaded_file = st.file_uploader(\"Upload a PDF or PPTX lecture\", type=[\"pdf\", \"pptx\"])\n",
    "    if uploaded_file:\n",
    "        file_path = os.path.join(LECTURE_NOTES_DIR, uploaded_file.name)\n",
    "        with open(file_path, \"wb\") as f:\n",
    "            f.write(uploaded_file.getbuffer())\n",
    "        chatbot.load_lecture(uploaded_file.name.split('.')[0].title(), file_path)\n",
    "        st.success(f\"Uploaded and loaded: {uploaded_file.name}\")\n",
    "    \n",
    "    # Scan directory for PDF and PPTX files\n",
    "    available_lectures = {}\n",
    "    try:\n",
    "        for file in os.listdir(LECTURE_NOTES_DIR):\n",
    "            if file.lower().endswith(('.pdf', '.pptx')):\n",
    "                lecture_name = os.path.splitext(file)[0].replace('_', ' ').title()\n",
    "                available_lectures[lecture_name] = os.path.join(LECTURE_NOTES_DIR, file)\n",
    "                \n",
    "        if not available_lectures:\n",
    "            st.error(f\"No PDF or PPTX files found in {LECTURE_NOTES_DIR}. Please upload or add lecture files.\")\n",
    "            return\n",
    "            \n",
    "        # Load available lectures\n",
    "        for name, path in available_lectures.items():\n",
    "            if name not in chatbot.knowledge_base.notes:\n",
    "                chatbot.load_lecture(name, path)\n",
    "        \n",
    "        # Lecture selection\n",
    "        lecture_name = st.selectbox(\"Select Lecture:\", list(available_lectures.keys()), key=\"lecture_select\")\n",
    "        \n",
    "        # Initialize session state for chat history\n",
    "        if \"messages\" not in st.session_state:\n",
    "            st.session_state.messages = []\n",
    "        \n",
    "        # Session ID for chat history\n",
    "        session_id = f\"{lecture_name}_session\"\n",
    "        \n",
    "        # Clear chat button\n",
    "        if st.button(\"Clear Chat\"):\n",
    "            st.session_state.messages = []\n",
    "            chatbot.clear_history(session_id)\n",
    "            st.rerun()\n",
    "        \n",
    "        # Display chat history\n",
    "        for idx, msg in enumerate(st.session_state.messages):\n",
    "            if msg[\"lecture\"] == lecture_name:\n",
    "                message(msg[\"content\"], is_user=(msg[\"role\"] == \"user\"), key=f\"msg_{idx}\")\n",
    "        \n",
    "        # Input form for question\n",
    "        with st.form(key=\"question_form\", clear_on_submit=True):\n",
    "            question = st.text_input(\"Ask a question about the lecture...\", key=\"question_input\")\n",
    "            submit_button = st.form_submit_button(\"Ask\")\n",
    "            \n",
    "            if submit_button and question.strip():\n",
    "                # Add user message\n",
    "                st.session_state.messages.append({\"role\": \"user\", \"content\": question, \"lecture\": lecture_name})\n",
    "                # Generate response\n",
    "                answer = chatbot.generate_response(lecture_name, question, session_id)\n",
    "                # Add assistant response\n",
    "                st.session_state.messages.append({\"role\": \"assistant\", \"content\": answer, \"lecture\": lecture_name})\n",
    "                # Rerun to update UI\n",
    "                st.rerun()\n",
    "                \n",
    "    except Exception as e:\n",
    "        st.error(f\"Error loading lectures from {LECTURE_NOTES_DIR}: {str(e)}\")\n",
    "# Run the chatbot\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4900dd3b-231c-427f-a6aa-348fdc79c55c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!streamlit run app.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f671d159-1ba4-49fa-bbc0-3897996c3edd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ctse_new_env)",
   "language": "python",
   "name": "ctse_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
