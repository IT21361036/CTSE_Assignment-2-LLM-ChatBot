{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4dff95a9-ddc4-490c-b105-1a5bdb98acb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from PyPDF2 import PdfReader\n",
    "import docx\n",
    "from pptx import Presentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "2b32ed6c-0894-4c6a-a4c0-249836d42ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores.faiss import FAISS\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.chains.combine_documents.stuff import StuffDocumentsChain\n",
    "from langchain_community.llms import HuggingFaceHub\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.docstore.document import Document\n",
    "from langchain.chains import AnalyzeDocumentChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "f9fe4699-2789-4f58-b842-d9a0f5f1d508",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "821a0aaa-0c1d-4b07-90ad-e57fe0341cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Text Loaders \n",
    "# Functions to read different file types\n",
    "def read_pdf(file_path):\n",
    "    with open(file_path, \"rb\") as file:\n",
    "        pdf_reader = PdfReader(file)\n",
    "        text = \"\"\n",
    "        for page_num in range(len(pdf_reader.pages)):\n",
    "            text += pdf_reader.pages[page_num].extract_text()\n",
    "    return text\n",
    "\n",
    "def read_word(file_path):\n",
    "    doc = docx.Document(file_path)\n",
    "    text = \"\"\n",
    "    for paragraph in doc.paragraphs:\n",
    "        text += paragraph.text + \"\\n\"\n",
    "    return text\n",
    "\n",
    "def read_txt(file_path):\n",
    "    with open(file_path, \"r\") as file:\n",
    "        text = file.read()\n",
    "    return text\n",
    "\n",
    "def read_pptx(file_path):\n",
    "    prs = Presentation(file_path)\n",
    "    text = \"\"\n",
    "    for slide in prs.slides:\n",
    "        for shape in slide.shapes:\n",
    "            if hasattr(shape, \"text\"):\n",
    "                text += shape.text + \"\\n\"\n",
    "    return text\n",
    "\n",
    "def read_documents_from_directory(directory):\n",
    "    combined_text = \"\"\n",
    "    for filename in os.listdir(directory):\n",
    "        file_path = os.path.join(directory, filename)\n",
    "        if filename.endswith(\".pdf\"):\n",
    "            combined_text += read_pdf(file_path)\n",
    "        elif filename.endswith(\".docx\"):\n",
    "            combined_text += read_word(file_path)\n",
    "        elif filename.endswith(\".txt\"):\n",
    "            combined_text += read_txt(file_path)\n",
    "        elif filename.endswith(\".pptx\"):\n",
    "            combined_text += read_pptx(file_path)\n",
    "    return combined_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "dc793495-20a6-4ad1-ac0d-fca225567a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_directory = 'train_files/'\n",
    "text = read_documents_from_directory(train_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "2899401d-e97f-4a2b-b299-277ed257a6cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into chunks\n",
    "char_text_splitter = CharacterTextSplitter(separator=\"\\n\", chunk_size=1000, chunk_overlap=200, length_function=len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "bd3ea78c-6c2f-4640-9bef-ed177410cce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_chunks = char_text_splitter.split_text(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "22d01882-8431-4955-8cfa-f6c39ca3d3d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create embeddings\n",
    "# Using HuggingFace embeddings instead of OpenAI\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "docsearch = FAISS.from_texts(text_chunks, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "7f7d7b3d-3ac7-414d-81f7-8b071304eb97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a prompt template for the LLM\n",
    "prompt_template = \"\"\"\n",
    "Given the following documents, answer the question as best as you can.\n",
    "\n",
    "Documents:\n",
    "{documents}\n",
    "\n",
    "Question: {question}\n",
    "Answer:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "fad5651c-71e2-48f9-91d9-2c8be7851abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Using HuggingFaceHub for the LLM\n",
    "llm = HuggingFaceHub(\n",
    "    repo_id=\"google/flan-t5-large\",  # Choose an appropriate model\n",
    "    model_kwargs={\"temperature\": 0.5, \"max_length\": 512},\n",
    "    huggingfacehub_api_token=os.environ.get(\"HUGGINGFACEHUB_API_TOKEN\")\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "1498c401-718e-4c81-a579-95883bb8908e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a PromptTemplate using the defined prompt\n",
    "prompt = PromptTemplate(input_variables=[\"documents\", \"question\"], template=prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "1b824da1-e4d3-4e1f-af22-e8abb64aaa29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the LLMChain\n",
    "llm_chain = LLMChain(llm=llm, prompt=prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "fd601179-5802-46a0-9822-9b336d4ebe32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the StuffDocumentsChain with the LLMChain\n",
    "chain = StuffDocumentsChain(\n",
    "    llm_chain=llm_chain,\n",
    "    document_variable_name=\"documents\"  # Tell it which input is for the documents\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "3caa2878-a1bc-4355-9f2e-c73d84edf5e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of how to run the chain\n",
    "query = \"What are the Main DevOps Practices\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "7208f69f-0946-4461-b150-6bff53866ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming you have already created a docsearch (FAISS vector store) for similarity search\n",
    "docs = docsearch.similarity_search(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "c9f7b069-4afb-4d21-9580-7b0e8e6a6525",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(id='580f3643-918d-4000-92f4-4e6db74b1f81', metadata={}, page_content='Silos\\nEveryones shares the ownership of \\nproduction and information is \\nshared among everyone\\nMeasure Everything\\nApplication, systems monitoring \\nand metrics etc... Implement Gradual \\nChanges\\nFrequent deployments, frequent \\ndeterministic releases in small \\nchunks which can be rolled backAccept Failure as Normal\\nBlameless PMs/ RCA. Risk taking \\nmindset.\\nLeverage Tooling and \\nAutomation\\nAutomate and reduce manual \\nwork as much as possibleKey Areas in DevOpsDevOps \\nPractices\\n•Continuous Integration (CI) -Software development practice where developers \\nregularly merge their code changes into a central repository, after which automated \\nbuilds and tests are run. \\n•Continuous Delivery (CD) -Software development practice where code changes are \\nautomatically built, tested, and prepared for a release to production (automated \\ncode change deployment to staging/ pre -production system). \\n•Continuous Deployment (CD) -Every change that passes all stages of the pipeline will'), Document(id='004a51d4-fa1a-48c9-99b5-8757dfd7b908', metadata={}, page_content='time analysis on the application status.DevOps Tools \\nand \\nTechnologiesBeyond\\nDevOps\"the practice of integrating security \\ninto a continuous integration, \\ncontinuous delivery, and continuous \\ndeployment pipeline\"DevSecOps\\nIdea of moving Security in the \\nearly stages of the SDLC \\npipeline\\nSRE (Site Reliability Engineering)\\n⚬Not competing with DevOps\\n⚬Think that Class SRE implements Interface DevOps\\n⚬SRE is a part of the DevOps umbrella\\nSRE Practices\\n-Identify and measure SLIs, define SLOs and agree/ commit to SLA for product and service\\n-Chaos Engineering\\n-Removing toil\\n-System designing (DR, Multi -Region, Mult -Cloud)\\n-Postmortems/ Root Cause Analysis\\n-ObservabilityPlatform Engineering\\nBefore jumping to definition, let’s understand the problem…\\n“The composition and integration of a set of processes, tools and automation \\n(components) to build a coherent platform with the goal of empowering developers to \\nbe able to easily build, maintain and deploy their business logic” Carrier as a'), Document(id='ac9eb891-a78f-47c8-b3a6-cde2cd0b7abf', metadata={}, page_content='the complexities behind \\ndevelopment and operations\\nAct 04 -Dev and Ops at war\\n\"It worked on my machine\" \\nphenomenon \"Destructive downward spiral in IT\" -Gene Kim\\nHow can we \\novercome \\nthese issues?“DevOps is the combination of cultural philosophies, practices, and tools \\nthat increases an organization’s ability to deliver applications and services \\nat high velocity”\\n-What is DevOps? [AWS] -\\n“A compound of development (Dev) and operations (Ops), DevOps is the \\nunion of people, process, and technology to continually provide value to \\ncustomers.” \\n-What is DevOps? [Azure] -\\nDevOps allows evolving and improving products at a faster pace than businesses \\nusing traditional software development and infrastructure management processes. \\nThis speed allows businesses to serve their customers better and compete effectively.Reduce Organizational \\nSilos\\nEveryones shares the ownership of \\nproduction and information is \\nshared among everyone\\nMeasure Everything\\nApplication, systems monitoring'), Document(id='a84c23e2-268a-42f1-baa6-a943cbc74a4c', metadata={}, page_content='⚬Policy as Code\\n•GitOps -builds on the concept of IaC, incorporating the functionality of Git \\nrepositories, merge requests (MRs) and CI/CD to further unify software development \\nand infrastructure operations. GitOps incorporates managing both infrastructure \\nand applications as code.\\n•Cloud Infrastructure -Cloud provides more flexibility, scalability and toolsets for \\norganizations to implement DevOps culture and practices. Serverless architecture in \\ncloud brings down  the efforts of DevOps teams as it eliminates server management \\noperations.\\n•Continuous Monitoring, Logging and Alerting -Organizations monitor metrics and logs \\nto see how application and infrastructure performance impacts the experience of \\ntheir product’s end user. Combined with real time alerts organizations can do a real \\ntime analysis on the application status.DevOps Tools \\nand \\nTechnologiesBeyond\\nDevOps\"the practice of integrating security \\ninto a continuous integration, \\ncontinuous delivery, and continuous')]\n"
     ]
    }
   ],
   "source": [
    "# Debug print to ensure docs is a list of strings\n",
    "print(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "1c4b6ca6-685d-4c2e-bd15-58e8e64aafb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrap each document content into a Document object\n",
    "docs = [Document(page_content=doc.page_content) for doc in docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "a8af10de-2768-4b1a-85fd-db049e742164",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\anaconda3\\envs\\ctse_env\\lib\\site-packages\\huggingface_hub\\utils\\_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
      "  warnings.warn(warning_message, FutureWarning)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Model 'google/flan-t5-large' doesn't support task 'text2text-generation'.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[169], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Now invoke the chain with the wrapped Document objects\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mchain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minput_documents\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mdocs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Pass the Document objects directly\u001b[39;49;00m\n\u001b[0;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mquestion\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mquery\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ctse_env\\lib\\site-packages\\langchain\\chains\\base.py:167\u001b[0m, in \u001b[0;36mChain.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    165\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    166\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n\u001b[1;32m--> 167\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[0;32m    168\u001b[0m run_manager\u001b[38;5;241m.\u001b[39mon_chain_end(outputs)\n\u001b[0;32m    170\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m include_run_info:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ctse_env\\lib\\site-packages\\langchain\\chains\\base.py:157\u001b[0m, in \u001b[0;36mChain.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    155\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_inputs(inputs)\n\u001b[0;32m    156\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m--> 157\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    158\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[0;32m    159\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(inputs)\n\u001b[0;32m    160\u001b[0m     )\n\u001b[0;32m    162\u001b[0m     final_outputs: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprep_outputs(\n\u001b[0;32m    163\u001b[0m         inputs, outputs, return_only_outputs\n\u001b[0;32m    164\u001b[0m     )\n\u001b[0;32m    165\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ctse_env\\lib\\site-packages\\langchain\\chains\\combine_documents\\base.py:138\u001b[0m, in \u001b[0;36mBaseCombineDocumentsChain._call\u001b[1;34m(self, inputs, run_manager)\u001b[0m\n\u001b[0;32m    136\u001b[0m \u001b[38;5;66;03m# Other keys are assumed to be needed for LLM prediction\u001b[39;00m\n\u001b[0;32m    137\u001b[0m other_keys \u001b[38;5;241m=\u001b[39m {k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m inputs\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_key}\n\u001b[1;32m--> 138\u001b[0m output, extra_return_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcombine_docs(\n\u001b[0;32m    139\u001b[0m     docs, callbacks\u001b[38;5;241m=\u001b[39m_run_manager\u001b[38;5;241m.\u001b[39mget_child(), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mother_keys\n\u001b[0;32m    140\u001b[0m )\n\u001b[0;32m    141\u001b[0m extra_return_dict[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_key] \u001b[38;5;241m=\u001b[39m output\n\u001b[0;32m    142\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m extra_return_dict\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ctse_env\\lib\\site-packages\\langchain\\chains\\combine_documents\\stuff.py:259\u001b[0m, in \u001b[0;36mStuffDocumentsChain.combine_docs\u001b[1;34m(self, docs, callbacks, **kwargs)\u001b[0m\n\u001b[0;32m    257\u001b[0m inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_inputs(docs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    258\u001b[0m \u001b[38;5;66;03m# Call predict on the LLM.\u001b[39;00m\n\u001b[1;32m--> 259\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm_chain\u001b[38;5;241m.\u001b[39mpredict(callbacks\u001b[38;5;241m=\u001b[39mcallbacks, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minputs), {}\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ctse_env\\lib\\site-packages\\langchain\\chains\\llm.py:319\u001b[0m, in \u001b[0;36mLLMChain.predict\u001b[1;34m(self, callbacks, **kwargs)\u001b[0m\n\u001b[0;32m    304\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, callbacks: Callbacks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[0;32m    305\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Format prompt with kwargs and pass to LLM.\u001b[39;00m\n\u001b[0;32m    306\u001b[0m \n\u001b[0;32m    307\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    317\u001b[0m \u001b[38;5;124;03m            completion = llm.predict(adjective=\"funny\")\u001b[39;00m\n\u001b[0;32m    318\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 319\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_key]\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ctse_env\\lib\\site-packages\\langchain_core\\_api\\deprecation.py:191\u001b[0m, in \u001b[0;36mdeprecated.<locals>.deprecate.<locals>.warning_emitting_wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    189\u001b[0m     warned \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    190\u001b[0m     emit_warning()\n\u001b[1;32m--> 191\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m wrapped(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ctse_env\\lib\\site-packages\\langchain\\chains\\base.py:386\u001b[0m, in \u001b[0;36mChain.__call__\u001b[1;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, run_name, include_run_info)\u001b[0m\n\u001b[0;32m    354\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Execute the chain.\u001b[39;00m\n\u001b[0;32m    355\u001b[0m \n\u001b[0;32m    356\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    377\u001b[0m \u001b[38;5;124;03m        `Chain.output_keys`.\u001b[39;00m\n\u001b[0;32m    378\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    379\u001b[0m config \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    380\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m: callbacks,\n\u001b[0;32m    381\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtags\u001b[39m\u001b[38;5;124m\"\u001b[39m: tags,\n\u001b[0;32m    382\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: metadata,\n\u001b[0;32m    383\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_name\u001b[39m\u001b[38;5;124m\"\u001b[39m: run_name,\n\u001b[0;32m    384\u001b[0m }\n\u001b[1;32m--> 386\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    387\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    388\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mRunnableConfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43mk\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    389\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_only_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_only_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    390\u001b[0m \u001b[43m    \u001b[49m\u001b[43minclude_run_info\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minclude_run_info\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    391\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ctse_env\\lib\\site-packages\\langchain\\chains\\base.py:167\u001b[0m, in \u001b[0;36mChain.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    165\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    166\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n\u001b[1;32m--> 167\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[0;32m    168\u001b[0m run_manager\u001b[38;5;241m.\u001b[39mon_chain_end(outputs)\n\u001b[0;32m    170\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m include_run_info:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ctse_env\\lib\\site-packages\\langchain\\chains\\base.py:157\u001b[0m, in \u001b[0;36mChain.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    155\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_inputs(inputs)\n\u001b[0;32m    156\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m--> 157\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    158\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[0;32m    159\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(inputs)\n\u001b[0;32m    160\u001b[0m     )\n\u001b[0;32m    162\u001b[0m     final_outputs: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprep_outputs(\n\u001b[0;32m    163\u001b[0m         inputs, outputs, return_only_outputs\n\u001b[0;32m    164\u001b[0m     )\n\u001b[0;32m    165\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ctse_env\\lib\\site-packages\\langchain\\chains\\llm.py:127\u001b[0m, in \u001b[0;36mLLMChain._call\u001b[1;34m(self, inputs, run_manager)\u001b[0m\n\u001b[0;32m    122\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_call\u001b[39m(\n\u001b[0;32m    123\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    124\u001b[0m     inputs: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any],\n\u001b[0;32m    125\u001b[0m     run_manager: Optional[CallbackManagerForChainRun] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    126\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mstr\u001b[39m]:\n\u001b[1;32m--> 127\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    128\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcreate_outputs(response)[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ctse_env\\lib\\site-packages\\langchain\\chains\\llm.py:139\u001b[0m, in \u001b[0;36mLLMChain.generate\u001b[1;34m(self, input_list, run_manager)\u001b[0m\n\u001b[0;32m    137\u001b[0m callbacks \u001b[38;5;241m=\u001b[39m run_manager\u001b[38;5;241m.\u001b[39mget_child() \u001b[38;5;28;01mif\u001b[39;00m run_manager \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    138\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm, BaseLanguageModel):\n\u001b[1;32m--> 139\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm\u001b[38;5;241m.\u001b[39mgenerate_prompt(\n\u001b[0;32m    140\u001b[0m         prompts,\n\u001b[0;32m    141\u001b[0m         stop,\n\u001b[0;32m    142\u001b[0m         callbacks\u001b[38;5;241m=\u001b[39mcallbacks,\n\u001b[0;32m    143\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm_kwargs,\n\u001b[0;32m    144\u001b[0m     )\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    146\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm\u001b[38;5;241m.\u001b[39mbind(stop\u001b[38;5;241m=\u001b[39mstop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm_kwargs)\u001b[38;5;241m.\u001b[39mbatch(\n\u001b[0;32m    147\u001b[0m         cast(\u001b[38;5;28mlist\u001b[39m, prompts), {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m: callbacks}\n\u001b[0;32m    148\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ctse_env\\lib\\site-packages\\langchain_core\\language_models\\llms.py:764\u001b[0m, in \u001b[0;36mBaseLLM.generate_prompt\u001b[1;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[0;32m    755\u001b[0m \u001b[38;5;129m@override\u001b[39m\n\u001b[0;32m    756\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mgenerate_prompt\u001b[39m(\n\u001b[0;32m    757\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    761\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    762\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m LLMResult:\n\u001b[0;32m    763\u001b[0m     prompt_strings \u001b[38;5;241m=\u001b[39m [p\u001b[38;5;241m.\u001b[39mto_string() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[1;32m--> 764\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerate(prompt_strings, stop\u001b[38;5;241m=\u001b[39mstop, callbacks\u001b[38;5;241m=\u001b[39mcallbacks, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ctse_env\\lib\\site-packages\\langchain_core\\language_models\\llms.py:971\u001b[0m, in \u001b[0;36mBaseLLM.generate\u001b[1;34m(self, prompts, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[0;32m    956\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m get_llm_cache() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[0;32m    957\u001b[0m     run_managers \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    958\u001b[0m         callback_manager\u001b[38;5;241m.\u001b[39mon_llm_start(\n\u001b[0;32m    959\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_serialized,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    969\u001b[0m         )\n\u001b[0;32m    970\u001b[0m     ]\n\u001b[1;32m--> 971\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate_helper(\n\u001b[0;32m    972\u001b[0m         prompts,\n\u001b[0;32m    973\u001b[0m         stop,\n\u001b[0;32m    974\u001b[0m         run_managers,\n\u001b[0;32m    975\u001b[0m         new_arg_supported\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mbool\u001b[39m(new_arg_supported),\n\u001b[0;32m    976\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    977\u001b[0m     )\n\u001b[0;32m    978\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(missing_prompts) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    979\u001b[0m     run_managers \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    980\u001b[0m         callback_managers[idx]\u001b[38;5;241m.\u001b[39mon_llm_start(\n\u001b[0;32m    981\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_serialized,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    988\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m missing_prompt_idxs\n\u001b[0;32m    989\u001b[0m     ]\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ctse_env\\lib\\site-packages\\langchain_core\\language_models\\llms.py:790\u001b[0m, in \u001b[0;36mBaseLLM._generate_helper\u001b[1;34m(self, prompts, stop, run_managers, new_arg_supported, **kwargs)\u001b[0m\n\u001b[0;32m    779\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_generate_helper\u001b[39m(\n\u001b[0;32m    780\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    781\u001b[0m     prompts: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mstr\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    786\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    787\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m LLMResult:\n\u001b[0;32m    788\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    789\u001b[0m         output \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m--> 790\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(\n\u001b[0;32m    791\u001b[0m                 prompts,\n\u001b[0;32m    792\u001b[0m                 stop\u001b[38;5;241m=\u001b[39mstop,\n\u001b[0;32m    793\u001b[0m                 \u001b[38;5;66;03m# TODO: support multiple run managers\u001b[39;00m\n\u001b[0;32m    794\u001b[0m                 run_manager\u001b[38;5;241m=\u001b[39mrun_managers[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m run_managers \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    795\u001b[0m                 \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    796\u001b[0m             )\n\u001b[0;32m    797\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[0;32m    798\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(prompts, stop\u001b[38;5;241m=\u001b[39mstop)\n\u001b[0;32m    799\u001b[0m         )\n\u001b[0;32m    800\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    801\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m run_manager \u001b[38;5;129;01min\u001b[39;00m run_managers:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ctse_env\\lib\\site-packages\\langchain_core\\language_models\\llms.py:1545\u001b[0m, in \u001b[0;36mLLM._generate\u001b[1;34m(self, prompts, stop, run_manager, **kwargs)\u001b[0m\n\u001b[0;32m   1542\u001b[0m new_arg_supported \u001b[38;5;241m=\u001b[39m inspect\u001b[38;5;241m.\u001b[39msignature(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call)\u001b[38;5;241m.\u001b[39mparameters\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m prompt \u001b[38;5;129;01min\u001b[39;00m prompts:\n\u001b[0;32m   1544\u001b[0m     text \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m-> 1545\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(prompt, stop\u001b[38;5;241m=\u001b[39mstop, run_manager\u001b[38;5;241m=\u001b[39mrun_manager, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1546\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[0;32m   1547\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(prompt, stop\u001b[38;5;241m=\u001b[39mstop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1548\u001b[0m     )\n\u001b[0;32m   1549\u001b[0m     generations\u001b[38;5;241m.\u001b[39mappend([Generation(text\u001b[38;5;241m=\u001b[39mtext)])\n\u001b[0;32m   1550\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m LLMResult(generations\u001b[38;5;241m=\u001b[39mgenerations)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ctse_env\\lib\\site-packages\\langchain_community\\llms\\huggingface_hub.py:138\u001b[0m, in \u001b[0;36mHuggingFaceHub._call\u001b[1;34m(self, prompt, stop, run_manager, **kwargs)\u001b[0m\n\u001b[0;32m    135\u001b[0m _model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_kwargs \u001b[38;5;129;01mor\u001b[39;00m {}\n\u001b[0;32m    136\u001b[0m parameters \u001b[38;5;241m=\u001b[39m {\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m_model_kwargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs}\n\u001b[1;32m--> 138\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpost\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    139\u001b[0m \u001b[43m    \u001b[49m\u001b[43mjson\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minputs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mparameters\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtask\u001b[49m\n\u001b[0;32m    140\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    141\u001b[0m response \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mloads(response\u001b[38;5;241m.\u001b[39mdecode())\n\u001b[0;32m    142\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124merror\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m response:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ctse_env\\lib\\site-packages\\huggingface_hub\\utils\\_deprecation.py:132\u001b[0m, in \u001b[0;36m_deprecate_method.<locals>._inner_deprecate_method.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    130\u001b[0m     warning_message \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m message\n\u001b[0;32m    131\u001b[0m warnings\u001b[38;5;241m.\u001b[39mwarn(warning_message, \u001b[38;5;167;01mFutureWarning\u001b[39;00m)\n\u001b[1;32m--> 132\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ctse_env\\lib\\site-packages\\huggingface_hub\\inference\\_client.py:302\u001b[0m, in \u001b[0;36mInferenceClient.post\u001b[1;34m(self, json, data, model, task, stream)\u001b[0m\n\u001b[0;32m    297\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    298\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot use `post` with another provider than `hf-inference`. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    299\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`InferenceClient.post` is deprecated and should not be used directly anymore.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    300\u001b[0m     )\n\u001b[0;32m    301\u001b[0m provider_helper \u001b[38;5;241m=\u001b[39m HFInferenceTask(task \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munknown\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 302\u001b[0m mapped_model \u001b[38;5;241m=\u001b[39m \u001b[43mprovider_helper\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_prepare_mapped_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    303\u001b[0m url \u001b[38;5;241m=\u001b[39m provider_helper\u001b[38;5;241m.\u001b[39m_prepare_url(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtoken, mapped_model)  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[0;32m    304\u001b[0m headers \u001b[38;5;241m=\u001b[39m provider_helper\u001b[38;5;241m.\u001b[39m_prepare_headers(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mheaders, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtoken)  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ctse_env\\lib\\site-packages\\huggingface_hub\\inference\\_providers\\hf_inference.py:35\u001b[0m, in \u001b[0;36mHFInferenceTask._prepare_mapped_model\u001b[1;34m(self, model)\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m model_id \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     31\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m     32\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTask \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtask\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m has no recommended model for HF Inference. Please specify a model\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     33\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m explicitly. Visit https://huggingface.co/tasks for more info.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     34\u001b[0m     )\n\u001b[1;32m---> 35\u001b[0m \u001b[43m_check_supported_task\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model_id\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ctse_env\\lib\\site-packages\\huggingface_hub\\inference\\_providers\\hf_inference.py:147\u001b[0m, in \u001b[0;36m_check_supported_task\u001b[1;34m(model, task)\u001b[0m\n\u001b[0;32m    145\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m task \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext-generation\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    146\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m--> 147\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m doesn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt support task \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtask\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pipeline_tag \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimage-text-to-text\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    150\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_conversational \u001b[38;5;129;01mand\u001b[39;00m task \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconversational\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "\u001b[1;31mValueError\u001b[0m: Model 'google/flan-t5-large' doesn't support task 'text2text-generation'."
     ]
    }
   ],
   "source": [
    "# Now invoke the chain with the wrapped Document objects\n",
    "response = chain.invoke({\n",
    "    \"input_documents\": docs,  # Pass the Document objects directly\n",
    "    \"question\": query\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e957370-6ed8-450a-9391-4a2bcb07ac69",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ctse_new_env)",
   "language": "python",
   "name": "ctse_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
